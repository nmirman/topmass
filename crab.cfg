[CRAB]

jobtype = cmssw
scheduler = condor
#scheduler = glite
#server_name = cern
#use_server = 1

[CMSSW]

### The data you want to access (to be found on DBS)
datasetpath=none

### The ParameterSet you want to use. For Madgraph, you don't really need anything here.
pset=none

### Splitting parameters
#total_number_of_events=100
number_of_jobs=200
events_per_job=1

### used to define random numbers
first_lumi=1

### The output files (comma separated list)
#output_file=fitresults.root, GlobalFit.root
#output_file=plotsTemplates.root
output_file=plotsFitResults.root, fitresults.root
#output_file=writeLikelihood.root

[USER]
#script_exe=scripts/RunGRID_data.sh
script_exe=scripts/condorjob.sh
#script_exe=scripts/RunCondorApresBig.sh

additional_input_files=forgrid.tar.gz
#additional_input_files=massfittingapres.tar.gz, /eos/uscms/store/user/shtan/calcedforgrid/massfittingcalced.tar.gz
#ui_working_dir = /uscms_data/d3/shtan/templateplots/fitsbootstrap/mt2_220
#ui_working_dir = /uscms_data/d3/shtan/templateplots/oct20code/combined172/mbl_mt2_220_maos210_maos220
ui_working_dir = /uscms_data/d3/shtan/templateplots/oct20code/wrong/172/mt2220
#ui_working_dir = /uscms_data/d3/shtan/templateplots/oct20code/statvalnov17/maos210_4

#ui_working_dir = /uscms_data/d3/shtan/jestest/dataVanillaApres_all_jun18

### OUTPUT files Management
#return_data = 1

# to store data on a storage element
return_data = 1
copy_data = 0

[GRID]
#ce_black_list=T0, T1
